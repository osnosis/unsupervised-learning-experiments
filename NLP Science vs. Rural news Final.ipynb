{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Science vs. Rural News\n",
    "\n",
    "For this challenge, I will choose a corpus of data from nltk that includes predictable categories and create an analysis pipeline that includes the following steps:\n",
    "\n",
    "- Data cleaning / processing / language parsing\n",
    "- Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "- Use the features to fit supervised learning models for each feature set to predict the category outcomes.\n",
    "- Assess your models using cross-validation and determine whether one model performed better.\n",
    "- Pick one of the models and try to increase accuracy by at least 5 percentage points.\n",
    "\n",
    "I will be looking at news clippings from the Australian Broadcast Center and using various Natural Language Processing methods to predict if a sentence from an unseen news clipping is categorized as 'rural' or 'science'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import abc\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning / processing / language parsing\n",
    "\n",
    "First, import rural/scientific news clips from text files. <br>\n",
    "Check length and show previews of content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Rural Doc: 1808022\n",
      "Length of Science Doc: 2246756\n",
      "\n",
      "PM denies knowledge of AWB kickbacks\n",
      "The Prime Minister has denied he knew AWB was paying kickbacks to Iraq despite writing to the wheat exporter asking to be kept fully informed on Iraq wheat sales.\n",
      "Letters from John Howard and Deputy Prime Minister Mark Vaile to AWB have been released by the Cole inquiry into the oil for food program.\n",
      "In one of the letters Mr Howard asks AWB managing director Andrew Lindberg to remain in close contact with the Government on Iraq wheat sales.\n",
      "The Opposition's Gavan O'Connor says the letter was sent in 2002, the same time AWB was paying kickbacks to Iraq though a Jordanian trucking company.\n",
      "He says the Government can longer wipe its hands of the illicit payments, which totalled $290 million.\n",
      "\"The responsibility for this must lay may squarely at the feet of Coalition ministers in trade, agriculture and the Prime Minister,\" he said.\n",
      "But the Prime Minister says letters show he was inquiring about the future of wheat sales in Iraq and do not prove the Government knew of the payments.\n",
      "\"It would have been astonishing in 2002 if as Prime Minister I hadn't done anything I possibly could to preserve Australia's very valuable wheat market,\" he said.\n",
      "\n",
      "Email questions\n",
      "Today at the inquiry, AWB trading manager Peter Geary has been questioned about an email he received in May 2000.\n",
      "It indicated that the Iraqi Grains Board had approached AWB to provide \"after-sales service\".\n",
      "Mr Geary said he had forwarded the email to two AWB colleagues and did not remember reading it, although he said he may have skimmed it.\n",
      "\n",
      "Support\n",
      "AWB still has plenty of support among grain growers in central western New South Wales despite the revelations of the Cole inquiry.\n",
      "Producers say they broadly support AWB's attempts to get the best prices for their products.\n",
      "\"I think it's all a ploy by overseas interests to try and get the single desk put aside. The stories that are going round about the commission and everything, I think that's the way people have got to do things to do business with the Middle East and Asian countries,\" one producer said.\n",
      "\"I think it's actually a pretty reasonable system and I think actually I'd give them pretty fair support at the moment. I think on average they've performed fairly well,\" another producer said.\n",
      "\"The biggest thing about someone else taking over is whether the multinationals will get too much of a foothold in there and take it too much to their advantage.\"\n",
      "\n",
      "Grain prices\n",
      "But an analyst predicts grain prices will drop another $20 a tonne on the back of the inquiry into AWB.\n",
      "Malcolm Bartholomaeus says pool returns have already dropped by $20 a tonne this year from the average price over the past five years.\n",
      "He says the premiums that AWB was achieving through its wheat export monopoly have been severely eroded.\n",
      "\n",
      "SA farmers help fire ravaged neighbours\n",
      "Farmers in South Australia's south-east are donating truckloads of hay to their neighbours across the border in the wake of the Grampians bushfires.\n",
      "In just a few days,\n",
      "\n",
      "Cystic fibrosis affects 30,000 children and young adults in the US alone\r\n",
      "Inhaling the mists of salt water can reduce the pus and infection that fills the airways of cystic fibrosis sufferers, although side effects include a nasty coughing fit and a harsh taste. \r\n",
      "That's the conclusion of two studies published in this week's issue of The New England Journal of Medicine.\r\n",
      "They found that inhaling a mist with a salt content of 7 or 9% improved lung function and, in some cases, produced less absenteeism from school or work. \r\n",
      "Cystic fibrosis, a progressive and frequently fatal genetic disease that affects about 30,000 young adults and children in the US alone, is marked by a thickening of the mucus which makes it harder to clear the lungs of debris and bacteria. \r\n",
      "The salt water solution \"really opens up a new avenue for approaching patients with cystic fibrosis and how to treat them,\" says Dr Gail Weinmann, of the US National Heart, Lung, and Blood Institute, which sponsored one of the studies. \r\n",
      "Mark Elkins of the Royal Prince Alfred Hospital in Sydney, Australia and colleagues authored one of the new published studies.\r\n",
      "The team found that the 83 volunteers who regularly inhaled a 7% mist of salty water had fewer breathing problems and less absenteeism from school or work than those who inhaled a solution with a salt content of under 1%. \r\n",
      "\"Adding salt [and water] to the airway surfaces of patients with cystic fibrosis is beneficial\" for both children and adults, they conclude. \r\n",
      "All of the patients first inhaled a chemical to try to open their lung passages as much as possible.\r\n",
      "In the second study, US-based Assistant Profsesor Scott Donaldson of the University of North Carolina at Chapel Hill and his colleagues found that a 7% salt mist \"produced a sustained acceleration of mucus clearance and improved lung function\" because it helped hydrate the lungs.\r\n",
      "In an accompanying editorial, Dr Felix Ratjen of the Hospital for Sick Children in Toronto, Canada, cited several unpleasant side effects of the salt mist treatment including a bad taste, coughing fits and the lengthy 30 minutes it can take to administer. \r\n",
      "He added that in the study by Elkins and team, patients may not have received the best long-term antibiotic treatment. \r\n",
      "That would make the inhaled salt water mist appear more effective than it would have been if people were getting a better drug, says Ratjen. \r\n",
      "Weinmann says limitations inherent to the treatment mean a salt water mist \"may be just a first step\" in treating cystic fibrosis.\r\n",
      "\r\n",
      "Scientists have rescued a mouse immune system that was overwhelmed by a systemic blood infection. But will this work in humans?\r\n",
      "Scientists have discovered how infections that invade the whole body, like malaria, disable the immune system and prevent it from detecting and fighting other microorganisms.\r\n",
      "The Australian and German researchers say the discovery may help scientists to develop vaccines that restore immunity in people with systemic or 'whol\n"
     ]
    }
   ],
   "source": [
    "rural = abc.raw('rural.txt')\n",
    "science = abc.raw('science.txt')\n",
    "\n",
    "print(f'Length of Rural Doc: {len(rural)}')\n",
    "print(f'Length of Science Doc: {len(science)}\\n')\n",
    "\n",
    "print(rural[:3000] + '\\n')\n",
    "print(science[:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At ~2 million chatacters each, these documents may be too long to be processed by my computer. I will shorten the length to 500,000 characters each. This may affect the accuracy of the classifier, but it will allow the program to run faster on my processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rural_short = rural[:500000]\n",
    "science_short = science[:500000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'd like to remove the heading titles from the documents, as they are not complete sentences and will skew the classifier's interpretation of what a sentence is. I will identify heading titles using a regular expression for 2 new lines, a sentence WITHOUT a full-stop, followed by another new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rural_no_head = re.sub(r'(\\n\\n+.[^\\.]+\\n)', ' ', rural_short)\n",
    "science_no_head = re.sub(r'(\\n\\n+.[^\\.]+\\n)', ' ', science_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, convert the documents to spacy tokens so we can extract lemmatized sentences, and filter out stop-words etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rural_spacy = nlp(rural_no_head)\n",
    "science_spacy = nlp(science_no_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0      1\n",
      "0              ['pm deny knowledge of awb kickback']  rural\n",
      "1  ['the prime minister have deny -PRON- know awb...  rural\n",
      "2  ['letters from john howard and deputy prime mi...  rural\n",
      "3  ['in one of the letter mr howard ask awb manag...  rural\n",
      "4  [\"the opposition have gavan o'connor say the l...  rural\n",
      "(7464, 2)\n"
     ]
    }
   ],
   "source": [
    "rural_lemma_sents = [[token.lemma_] for token in rural_spacy.sents]\n",
    "science_lemma_sents = [[token.lemma_] for token in science_spacy.sents]\n",
    "\n",
    "\n",
    "rural_str_sents = [[str(sent), 'rural'] for sent in rural_lemma_sents]\n",
    "science_str_sents = [[str(sent), 'science'] for sent in science_lemma_sents]\n",
    "\n",
    "sentences_df = pd.DataFrame(rural_str_sents + science_str_sents)\n",
    "print(sentences_df.head())\n",
    "print(sentences_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "Creating a pipeline will complete the following core objectives:\n",
    "- Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "- Use the features to fit supervised learning models for each feature set to predict the category outcomes.\n",
    "- Assess your models using cross-validation and determine whether one model performed better.\n",
    "\n",
    "I will create a pipeline that implements a gridsearch to determine the best techniques and parameters for feature generation and classification. The first step in the pipeline will be feature generation, implementing either bag-of-words or tf-idf vectorizer. The second step in the pipeline will be fitting the feature sets to supervised learning models for random forest and logistic regression. The grid search will implement cross-validation and return the parameters for the model with the best performance (highest accuracy score). I will then use those parameters to validate the model on an unseen validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = sentences_df[0]\n",
    "Y = sentences_df[1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.8,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_min_df = [0.25, 0.5, 0.75]\n",
    "cv_max_df = [0.25, 0.5, 0.75]\n",
    "cv_max_features = [100, 500, 1000, None]\n",
    "\n",
    "tfidf_min_df = [0.25, 0.5, 0.75]\n",
    "tfidf_max_df = [0.25, 0.5, 0.75]\n",
    "tfidf_max_features = [100, 500, 1000, None]\n",
    "\n",
    "rf_depth_max = [None, 10,100, 1000]\n",
    "rf_ft_max = [None, 100, 1000]\n",
    "rf_min_splits = [2, 10, 100, 1000]\n",
    "rf_n_trees = [10, 50]\n",
    "\n",
    "logistic_c = [1e-3, 1e-2, 1e-1, 1, 10, 50, 100, 1000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('create_feat', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "      ...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'create_feat': [CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=None, min_df=5,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='engl...     verbose=0, warm_start=False)], 'classify__C': [0.001, 0.01, 0.1, 1, 10, 50, 100, 1000, 10000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "        ('create_feat', CountVectorizer()),\n",
    "        ('classify', RandomForestClassifier())\n",
    "         ])\n",
    "\n",
    "cv_min_df = [1, 5]\n",
    "cv_max_df = [0.5, 0.75]\n",
    "cv_max_features = [100, 500, None]\n",
    "\n",
    "tfidf_min_df = [1, 5]\n",
    "tfidf_max_df = [0.5, 0.75]\n",
    "tfidf_max_features = [100, 500, None]\n",
    "\n",
    "rf_depth_max = [None, 10,100, 1000]\n",
    "rf_ft_max = [None, 100, 500]\n",
    "rf_min_splits = [2, 10, 100, 1000]\n",
    "rf_n_trees = [10, 50]\n",
    "\n",
    "logistic_c = [1e-3, 1e-2, 1e-1, 1, 10, 50, 100, 1000, 10000]\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'create_feat': [CountVectorizer(stop_words='english',analyzer='word')],\n",
    "        'create_feat__min_df': cv_min_df,\n",
    "        'create_feat__max_df': cv_max_df,\n",
    "        'create_feat__max_features': cv_max_features,\n",
    "        'classify': [RandomForestClassifier()],\n",
    "        'classify__max_depth': rf_depth_max,\n",
    "        #'classify__max_features': rf_ft_max,\n",
    "        'classify__min_samples_split': rf_min_splits,\n",
    "        'classify__n_estimators': rf_n_trees\n",
    "    },\n",
    "    {\n",
    "        'create_feat': [TfidfVectorizer(stop_words='english',analyzer='word')],\n",
    "        'create_feat__min_df': tfidf_min_df,\n",
    "        'create_feat__max_df': tfidf_max_df,\n",
    "        'create_feat__max_features': tfidf_max_features,\n",
    "        'classify': [RandomForestClassifier()],\n",
    "        'classify__max_depth': rf_depth_max,\n",
    "        #'classify__max_features': rf_ft_max,\n",
    "        'classify__min_samples_split': rf_min_splits,\n",
    "        'classify__n_estimators': rf_n_trees\n",
    "    },\n",
    "    {\n",
    "        'create_feat': [CountVectorizer(stop_words='english',analyzer='word')],\n",
    "        'create_feat__min_df': cv_min_df,\n",
    "        'create_feat__max_df': cv_max_df,\n",
    "        'create_feat__max_features': cv_max_features,\n",
    "        'classify': [LogisticRegression()],\n",
    "        'classify__C': logistic_c\n",
    "    },\n",
    "        {\n",
    "        'create_feat': [TfidfVectorizer(stop_words='english',analyzer='word')],\n",
    "        'create_feat__min_df': tfidf_min_df,\n",
    "        'create_feat__max_df': tfidf_max_df,\n",
    "        'create_feat__max_features': tfidf_max_features,\n",
    "        'classify': [LogisticRegression()],\n",
    "        'classify__C': logistic_c\n",
    "    },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, cv=3, n_jobs=1, param_grid=param_grid)\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:\n",
      " {'classify': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), 'classify__C': 1, 'create_feat': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None), 'create_feat__max_df': 0.75, 'create_feat__max_features': None, 'create_feat__min_df': 1}\n",
      "best score:\n",
      " 0.8820375335120644\n"
     ]
    }
   ],
   "source": [
    "print(f'best params:\\n {grid.best_params_}')\n",
    "print(f'best score:\\n {grid.best_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best method of feature generation was tf-idf vectorizer, and the best method of classification was logistic regression with default C=1. This generated a cross-validated training score of **0.882**. Let's see how this model performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('create_feat', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.set_params(create_feat=TfidfVectorizer(stop_words='english',analyzer='word'),\n",
    "                create_feat__min_df=1,\n",
    "                create_feat__max_df=0.75,\n",
    "                create_feat__max_features=None).fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.8039182853315472\n"
     ]
    }
   ],
   "source": [
    "test_pred = pipe.predict(X_test)\n",
    "print(f'Testing Accuracy: {accuracy_score(Y_test, test_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model seems to be overfitting a lot! The cross-validated training score is 0.882, yet the testing score is only **0.804**. \n",
    "\n",
    "# Pick one of the models and try to increase accuracy by at least 5 percentage points\n",
    "\n",
    "Let's try to improve this model by filtering down the gridsearch to just tfidf and logistic, and adding more variety the hyperparameters for these techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipe2 = Pipeline([\n",
    "        ('create_feat', TfidfVectorizer()),\n",
    "        ('classify', LogisticRegression())\n",
    "         ])\n",
    "\n",
    "tfidf_min_df2 = [1, 2, 5, 10]\n",
    "tfidf_max_df2 = [0.5, 0.6,0.7, 0.75, 0.8]\n",
    "tfidf_max_features2 = [50, 100, 150, None]\n",
    "\n",
    "logistic_c2 = [1e-3, 1e-2, 1e-1, 1, 10, 50, 100, 1000, 10000]\n",
    "\n",
    "param_grid2 = [\n",
    "        {\n",
    "        'create_feat': [TfidfVectorizer(stop_words='english',analyzer='word')],\n",
    "        'create_feat__min_df': tfidf_min_df2,\n",
    "        'create_feat__max_df': tfidf_max_df2,\n",
    "        'create_feat__max_features': tfidf_max_features2,\n",
    "        'classify': [LogisticRegression()],\n",
    "        'classify__C': logistic_c\n",
    "    },\n",
    "]\n",
    "\n",
    "grid2 = GridSearchCV(pipe2, cv=3, n_jobs=1, param_grid=param_grid2)\n",
    "grid2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:\n",
      " {'classify': LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), 'classify__C': 1, 'create_feat': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.6, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None), 'create_feat__max_df': 0.6, 'create_feat__max_features': None, 'create_feat__min_df': 1}\n",
      "best score:\n",
      " 0.8820375335120644\n"
     ]
    }
   ],
   "source": [
    "print(f'best params:\\n {grid2.best_params_}')\n",
    "print(f'best score:\\n {grid2.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.8879772270596116\n"
     ]
    }
   ],
   "source": [
    "pipe2.set_params(create_feat=TfidfVectorizer(stop_words='english',analyzer='word'),\n",
    "                create_feat__min_df=1,\n",
    "                create_feat__max_df=0.6,\n",
    "                create_feat__max_features=None).fit(X_train,Y_train)\n",
    "test_pred2 = pipe2.predict(X_test)\n",
    "print(f'Testing Accuracy: {accuracy_score(Y_test, test_pred2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow -- just decreasing the max_df from 0.75 to 6 had very little effect on our cross-validated training score (both 0.882) but had a significant effect on our testing score, which increased from 0.804 to **0.888.** We have achieved our goal of improving the score by 5 points!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Implementing a pipeline with grid search was the most efficient way to classify rural vs. science news on a per-sentence basis. I offered two options for feature generation (bag-of-words and tfidf vectorizer) and two options for classification (random forest and logistic regression). I chose the best model by looking at the cross-validation score on the training dataset (75% of the data) then feeding unseen test data into the trained model. Tfidf-vectorization with logistic regression was the best-performing model with a cross-validation score of 0.882 and a final testing score of **0.888.** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
